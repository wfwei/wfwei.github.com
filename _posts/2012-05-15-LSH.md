---
layout: post
title: "Locality Sensitive Hashing"
categories: posts 
---

## Locality-Sensitive Hashing(LSH)
    
***Basic idea***: hash the input items so that **similar items are mapped to the same buckets with high probability**
*** Application: ***
	   
1. probabilistic dimension reduction of high-dimensional data
2. *approximate* nearest neighbor
	
***implementation methods***
	
1. Bit sampling for Hamming distance
2. Min-wise independent permutations
3. Random projection
4. Stable distributions
		
***Random Projection***
	
The random projection method of LSH is designed to approximate the cosine distance between vectors.
The basic idea of this technique is to choose a random hyperplane (defined by a normal unit vector ) at the outset and use the hyperplane to hash input vectors.
		
1. 选取k个hyperplane，构成2^k个bucket
2. 每个hyperplane都从高斯分布（比如N(0,1)）中random出一个向量u
3. 对于每个document，提取feature，构成一个向量v
4. 计算h(v)=v*u,通过sgn(h(v))的符号判断v在u所代表平面的哪一侧

   按照这样的策略，两个document x,y被分到同一侧（认为collision）的概率是：`p= Pr(h(x)=h(y)) = 1-theta(x,y)/PI ---- theta(x,y) is the angle between x and y`
			
5. 每个document都在k个平面上利用4中方法计算，形成一次映射projection
		
   一次映射后，x,y被映射到同一个bucket的概率是p'=p^k，指数速度变小了
			
6. 一次映射后，p'是很小的，这很可能把locality-sensitive的点分到不同的bucket中
7. 可以做L次映射，只要在一次映射中最近邻被分到同一个bucket就可以了
8. 在给定平面数目k和最近邻被分到不同bucket的期望概率w的情况下，可以得到：
	
    `(1-p')^L = w`
	    
***注意点：***
		
1. k的大小影响到粒度，需要实际调节
2. 1-theta(x,y)/PI 和 cos(x,y) 的关系使得本方法中，locality-sensitive中的距离是指两个vector的cosin
3. w的大小影响到hash的效果，需实际调节

***参考:***

[LSH@wikipedia](http://en.wikipedia.org/wiki/Locality-sensitive_hashing)

[locality sensitive hashing for finding nearest neighbors](https://scholar.google.com)

[Streaming First Story Detection with application to Twitter](https://scholar.google.com)

