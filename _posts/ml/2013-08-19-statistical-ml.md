---
layout: post
title: "统计机器学习"
categories: [ml]
---

###机器学习分类

* [监督学习 Supervised Learning](/posts/supervised-learning)  训练数据都有标签信息，主要包括分类，标记和回归问题
  * 回归问题，输入，输出都是连续变量的预测问题
  * 分类问题，输出为有限个离散变量的预测问题，
  * 标记问题，输入，输出都是变量序列的预测问题，如词性标注问题

* 非监督学习 Unsupervised learning
    训练数据不含有标签信息，如聚类问题

* 半监督学习 Semi-Supervised Learning
    训练数据含有部分标签信息，在训练数据十分稀少的情况下，通过利用一些没有类标的数据，提高学习准确率的方法。

* 强化学习 Reinforcement Learning
    Rewards from sequence of actions

* 主动学习 Active Learning
    当含有标签的训练数据缺少的时候，主动学习算法会推荐出比较重要的数据，之后人工标注，之后在训练

###统计学习假设

统计机器学习假设数据存在一定统计规律

监督学习假设输入输出随机变量X,Y，遵循联合概率分布P(X,Y)，训练数据和测试数据被看作是依照联合概率分布P(X,Y)，独立同分布产生的

###统计学习三要素

统计学习方法 = 模型 + 策略 + 算法

1. 模型，在监督学习中就是指数据的条件概率分布(生成模型)，或决策函数(判别模型)
2. 策略，学习或选择最优模型的准则，主要指确定模型的损失函数，风险函数
3. 算法，模型的具体计算方法，如常见的梯度下降，牛顿下降，EM等

###结构风险 vs 经验风险

结构化风险 = 经验风险 + 置信风险

  * 经验风险 =  分类器在给定样本上的误差
  * 置信风险 = 分类器在未知文本上分类的结果的误差

优化理论中，最小化结构化风险，主要是最小化样本上的经验风险，如果考虑防止过拟合，可以添加正则项，同时最小化置信风险

当样本容量足够大时，经验风险趋近于结构风险，经验风险最小化就能保证足够好的学习效果，在现实中被广泛使用

极大似然估计就是经验风险最小化的例子：当模型是条件概率分布，损失函数为对数损失函数，经验风险最小化就等价于极大似然估计

但，当样本较小时，经验风险最小化学习容易‘过拟合’

结构风险最小化就是为了防止过拟合而提出的策略，其在经验风险上加上表示模型复杂度的**正则项(罚项)**

贝叶斯估计中，最大后验概率估计就是结构化风险最小化的例子：当模型是条件概率分布，损失函数为对数损失函数，模型的复杂度由模型的先验概率表示，结构风险最小化就等价于最大后验概率估计

