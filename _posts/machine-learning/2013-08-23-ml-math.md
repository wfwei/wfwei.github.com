---
layout: post
title: "机器学习中的数学"
categories: [ml, geometric]
---

这篇笔记主要记录机器学习中的常用数学：

1. 几何运算
    1. 矩阵秩
    2. 矩阵运算
    3. 矩阵梯度

2. 分布
    1. 高斯分布
    1. 伯努力分布(0-1分布)
    1. 二项分布

3. 期望，方差，协方差，相关系数

##常用的几何运算(Geometric Operation)

几个共用变量：

$$A_{m*n} = 
\begin{pmatrix}
A_{11} & A_{12} & \cdots & A_{1n} \\
A_{21} & A_{22} & \cdots & A_{2n} \\
\vdots& \vdots & \ddots & \vdots \\
A_{m1} & A_{12} & \cdots & A_{mn}    
\end{pmatrix}$$

$$function~f:~\Re^{m*n} \mapsto \Re$$

###1. 矩阵秩

假设m=n，A的秩为：$$tr A = \sum_{i=1}^{n} A_{ii} $$

* 如果A是m×n，B是n×m的矩阵，则有: $$tr AB = tr BA$$
* 方阵A：$$tr A = tr A^T $$
* 对于方阵A,B: $$tr A+B = tr A + tr B $$
* 乘上alpha系数：$$tr \alpha A = \alpha tr A$$

###2. 矩阵运算


#### 矩阵加法

#### 矩阵乘法

矩阵间乘法满足：

1. 结合率: $$(AB)C=A(BC)$$ 有常数时，$$(\lambda A)B=A(\lambda B)$$
2. 分配率: $$A(B+C)=AB+AC$$ 或 $$(A+B)C=AC+BC$$

**不满足**

1. 交换率: $$AB$$有意义，但$$BA$$不一定有意义，且即便有意义，也不一定有$$AB=BA$$，正因为如此，$$(A+B)^2 \neq A^2+2AB+B^2$$

[更多参考](http://web.tongji.edu.cn/~math/xxds/kcja/kcja_a/01.htm)

###3. 矩阵梯度

$$
\frac{\partial f(A)}{\partial A_{m*n}} = 
\begin{pmatrix}
\frac{\partial f}{\partial A_{11}} & \frac{\partial f}{\partial A_{12}} & \cdots & \frac{\partial f}{\partial A_{1n}} \\
\frac{\partial f}{\partial A_{21}} & \frac{\partial f}{\partial A_{22}} & \cdots & \frac{\partial f}{\partial A_{2n}} \\
\vdots& \vdots & \ddots & \vdots \\
\frac{\partial f}{\partial A_{m1}} & \frac{\partial f}{\partial A_{12}} & \cdots & \frac{\partial f}{\partial A_{mn}}  
\end{pmatrix}
$$

例子：
A是2×2的矩阵，$$f(A)=\frac32 A_{11} + 5A_{12}^2 + A_{21}A_{22}$$，则有：

**注意**，这里$$f(A)$$是一个‘纲量’，即不是向量或矩阵

$$
\frac{\partial f(A)}{\partial A} = 
\begin{pmatrix}
\frac32 & 10 A_{12} \\
 A_{22} & A_{21}
\end{pmatrix}
$$

常用等式：

$$\nabla_{A^T} f(A) = (\nabla_A f(A))^T$$

$$\nabla_A \| A \| = \| A \| (A^{-1})^T$$

$$\nabla_A tr AB = B^T$$

$$\nabla_A tr ABA^TC = CAB+C^TAB^T$$

##常用的分布

###高斯分布

高斯分布，也称正太分布

1. 一维高斯分布
  分布：$$ N(\mu,\sigma)$$，其中$$\mu$$是期望，$$\sigma$$是方差  
  密度函数为：$$p(x;\mu,\sigma)=\frac1{\sigma\sqrt{2\pi}} exp\{ -\frac{(x-\mu)^2}{2\sigma^2}  \}$$

2. 高维高斯分布
  分布：$$\mathcal{N}(\vec{\mu},\Sigma)$$，其中，$$\vec{\mu}$$是期望向量，$$\Sigma$$是对称半正定协方差矩阵  
  密度函数：$$p(\vec{x};\vec{\mu},\Sigma)=\frac1{\left | \Sigma \right | ^{1/2} (2\pi)^{n/2}} exp\{ -\frac12 (\vec{x}-\vec{\mu})^T \Sigma^{-1} (\vec{x}-\vec{\mu})  \}$$

###伯努利分布(the Bernoulli distribution)

伯努利分布也称为0-1分布, 是指随机变量仅仅取值0和1的离散概率分布.

###二项分布(Binaomial Distribution)

二项分布即重复n次的伯努利试验。在每次试验中只有两种可能的结果，而且是互相对立的，是独立的，与其它各次试验结果无关，结果事件发生的概率在整个系列试验中保持不变，则这一系列试验称为伯努利实验。

##期望，方差，协方差，相关系数

设X,Y是两个独立的随机变量，我们获取一组(X,Y)的观测集合$$ D={(x_1, y_1), (x_2, y_2),..,(x_n, y_n)} $$

>当观测集合足够大的时候，我们可以认为观测数据可以很好的表示原始数据分布，因此可以利用观测数据上的期望，方差代表原始数据的期望和方差

###基本概念

1. 期望(Expectation):即随机变量取值的均值

    $$ EX = \frac1N \sum_{i=1}^N x_i \\  EY = \frac1N \sum_{i=1}^N y_i $$

2. 方差：描述随机变量的取值和其期望的偏离程度

    $$
    \begin{array}{l l l}
    Var(X) & = & E((X-E(X))^2) \\
           & = & E(X^2-2XE(X)+(E(X))^2) \\
           & = & E(X^2)-2E(X)E(X)+(E(X))^2 \\
           & = & E(X^2)-2(E(X))^2+(E(X))^2 \\
           & = & E(X^2)-(E(X))^2
    \end{array}
    $$

3. 协方差：衡量两个随机变量的偏离程度

    $$ Cov(X, Y) = E((X-EX)(Y-EY) = E(XY)-E(X)E(Y)$$

    方差是在$$X=Y$$时的协方差，即$$Cov(X,X)=Var(X)$$

    协方差性质：

    1. 独立随机变量的协方差为0
    2. 线性组合:$$Cov(\sum_{i=1}^m{a_iX_i}, \sum_{j=1}^n{b_jY_j})=\sum_{i=1}^m{\sum_{j=1}^n{a_i b_j Cov(X_i, Y_j)}}$$

4. 相关系数：衡量两个随机变量的线性相关程度[-1, 1]，1,-1分别表示正负相关，0表示线性不相关
    $$Corr(X,Y)=\frac{Cov(X,Y)}{\sqrt{Var(X)Var(Y)}}$$

###计算协方差

TODO 整理 [1](http://www.cnblogs.com/jerrylead/archive/2011/04/18/2020209.html),[2](http://blog.codinglabs.org/articles/pca-tutorial.html),[3](http://blog.csdn.net/ybdesire/article/details/6270328)




