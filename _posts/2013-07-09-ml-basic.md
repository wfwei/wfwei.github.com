---
layout: post
title: "Machine Leaning Basics"
category: posts
---
###二次规划
* 一类特殊的非线性规划
* 目标函数是二次函数，约束条件是线性的
* 一般形式:
    
    min f(x)= 1/2 * x_T * Q * x + c_T * x
    s.t. Ax<b

###正定矩阵
* 正定二次型    对于非零的向量取值恒大于0的二次型 
    * 设`Q(x)=x^T * A * x`是一个二次型，如果对于任何x!=0，都有Q(x)>0，则为正定二次型
    * 正定二次型Q中的矩阵A的特征值全部大于0
    * 半正定二次型 取值大于等于0，A的特征中大于等于0
* 正定矩阵  可以构成正定二次型的矩阵（上面的A）
    * 正定矩阵的特征值都大于0

###最大方差理论
* 在信号处理中认为信号具有较大的方差，噪声有较小的方差，信噪比就是信号与噪声的方差比，越大越好。

###[拉格朗日乘数](https://zh.wikipedia.org/wiki/%E6%8B%89%E6%A0%BC%E6%9C%97%E6%97%A5%E4%B9%98%E6%95%B0)
* 将有n个变量，k个约束条件的最优化问题转化为n+k个变量的方程组极值问题，其变量不受约束
* 该方法引入新的标量未知数，成为拉格朗日乘数
* 简单例子：
    * 最大(小)化 f(x,y) 受限于 g(x,y)=c
    * 引入拉格朗日乘数lambda,将问题转化为无约束机制问题：k(x,y,lambda)=f(x,y)+lambda\*(g(x,y)-c)

###松弛求解
在实验数据处理和曲线拟合问题中，求解超定方程组非常普遍。这时常常需要退一步，将线性方程组的求解问题改变为求最小误差的问题。形象的说，就是在无法完全满足给定的这些条件的情况下，求一个最接近的解。比较常用的方法是最小二乘法。最小二乘法求解超定问题等价于一个优化问题，或者说最小值问题，即，在不存在x使得Ax-b=0的情况下，我们试图找到这样的x使得|Ax-b|最小，其中|·|表示范数。

###模拟退火(SA,Simulated Annealing)
* 模拟退火是一种贪心算法，但是它的搜索过程引入了随机因素
* 模拟退火算法以一定的概率来接受一个比当前解要差的解，因此有可能会跳出局部的最优解，达到全局的最优解。
* 这个概率随着时间推移逐渐降低，这样才能趋于稳定
* 区别于爬山算法(Hill Climbing)，爬山算法是一种简单的贪心搜索算法，该算法每次从当前解的临近解空间中选择一个最优解作为当前解，直到达到一个局部最优解。
* [more](http://www.cnblogs.com/heaad/archive/2010/12/20/1911614.html)
